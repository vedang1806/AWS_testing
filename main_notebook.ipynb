{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cd9d24",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe56f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3 botocore python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any, List, Tuple\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import requests\n",
    "from pydub import AudioSegment\n",
    "from pydub.generators import Sine\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e4438e",
   "metadata": {},
   "source": [
    "## 1.5 Setup Credentials (Required for Google Colab)\n",
    "\n",
    "**Important:** If running in Google Colab, you need to set up your credentials first.\n",
    "\n",
    "Choose one of the following methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7fd82",
   "metadata": {},
   "source": [
    "### Method 1: Use Google Colab Secrets (Recommended)\n",
    "\n",
    "1. Click the üîë key icon in the left sidebar\n",
    "2. Add these secrets:\n",
    "   - `AWS_ACCESS_KEY_ID`\n",
    "   - `AWS_SECRET_ACCESS_KEY`\n",
    "   - `AWS_S3_BUCKET_NAME`\n",
    "   - `AWS_S3_REGION`\n",
    "   - `GEMINI_API_KEY`\n",
    "3. Enable notebook access for each secret\n",
    "4. Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d5e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Load from Google Colab Secrets\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = userdata.get('AWS_ACCESS_KEY_ID')\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
    "    os.environ['AWS_S3_BUCKET_NAME'] = userdata.get('AWS_S3_BUCKET_NAME')\n",
    "    os.environ['AWS_S3_REGION'] = userdata.get('AWS_S3_REGION')\n",
    "    os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
    "    os.environ['ENVIRONMENT'] = 'COLAB'\n",
    "\n",
    "    print(\"‚úÖ Credentials loaded from Colab Secrets\")\n",
    "except ImportError:\n",
    "    print(\"‚ÑπÔ∏è  Not running in Colab - will use .env file or manual setup\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not load from Colab Secrets: {e}\")\n",
    "    print(\"   Please use Method 2 or 3 below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713c91b",
   "metadata": {},
   "source": [
    "### Method 2: Upload .env File\n",
    "\n",
    "Upload your `.env` file to Colab and run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b402f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Upload .env file\n",
    "try:\n",
    "    from google.colab import files\n",
    "\n",
    "    print(\"üì§ Please upload your .env file:\")\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    if '.env' in uploaded:\n",
    "        with open('.env', 'wb') as f:\n",
    "            f.write(uploaded['.env'])\n",
    "\n",
    "        # Reload environment variables\n",
    "        load_dotenv(override=True)\n",
    "        print(\"‚úÖ .env file uploaded and loaded successfully\")\n",
    "    else:\n",
    "        print(\"‚ùå No .env file found in upload\")\n",
    "except ImportError:\n",
    "    print(\"‚ÑπÔ∏è  Not running in Colab - skipping file upload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c1b7b",
   "metadata": {},
   "source": [
    "### Method 3: Manual Entry (Secure Input)\n",
    "\n",
    "Manually enter your credentials using secure input fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Manual credential entry with secure input\n",
    "from getpass import getpass\n",
    "\n",
    "print(\"üîê Enter your credentials (input will be hidden):\\n\")\n",
    "\n",
    "# Check if credentials are already set\n",
    "if not os.getenv('AWS_ACCESS_KEY_ID'):\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = getpass('AWS Access Key ID: ')\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = getpass('AWS Secret Access Key: ')\n",
    "    os.environ['AWS_S3_BUCKET_NAME'] = input('S3 Bucket Name (default: bpo-project-bucket): ') or 'bpo-project-bucket'\n",
    "    os.environ['AWS_S3_REGION'] = input('AWS Region (default: us-east-1): ') or 'us-east-1'\n",
    "    os.environ['GEMINI_API_KEY'] = getpass('Gemini API Key: ')\n",
    "    os.environ['ENVIRONMENT'] = 'COLAB'\n",
    "\n",
    "    print(\"\\n‚úÖ Credentials set successfully\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Credentials already configured (skipping manual entry)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c089f4",
   "metadata": {},
   "source": [
    "### Verify Credentials\n",
    "\n",
    "Run this cell to verify your credentials are properly configured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59989c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all required credentials are set\n",
    "required_vars = {\n",
    "    'AWS_ACCESS_KEY_ID': os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "    'AWS_SECRET_ACCESS_KEY': os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "    'AWS_S3_BUCKET_NAME': os.getenv('AWS_S3_BUCKET_NAME'),\n",
    "    'AWS_S3_REGION': os.getenv('AWS_S3_REGION'),\n",
    "    'GEMINI_API_KEY': os.getenv('GEMINI_API_KEY')\n",
    "}\n",
    "\n",
    "print(\"üîç Credential Status:\\n\")\n",
    "all_set = True\n",
    "for var_name, var_value in required_vars.items():\n",
    "    if var_value:\n",
    "        # Show partial value for security\n",
    "        if 'KEY' in var_name or 'SECRET' in var_name:\n",
    "            display_value = f\"{var_value[:4]}...{var_value[-4:]}\" if len(var_value) > 8 else \"***\"\n",
    "        else:\n",
    "            display_value = var_value\n",
    "        print(f\"‚úÖ {var_name}: {display_value}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {var_name}: NOT SET\")\n",
    "        all_set = False\n",
    "\n",
    "if all_set:\n",
    "    print(\"\\n‚úÖ All credentials are configured!\")\n",
    "    print(\"   You can now proceed with the rest of the notebook\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some credentials are missing!\")\n",
    "    print(\"   Please use one of the methods above to set them\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45bd18",
   "metadata": {},
   "source": [
    "## 2. Configuration and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Configuration\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_S3_BUCKET_NAME = os.getenv(\"AWS_S3_BUCKET_NAME\", \"bpo-box-dev\")\n",
    "AWS_S3_REGION = os.getenv(\"AWS_S3_REGION\", \"us-east-1\")\n",
    "ENVIRONMENT = os.getenv(\"ENVIRONMENT\", \"LOCAL\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# PII Entity Types to Detect\n",
    "PII_ENTITY_TYPES = [\n",
    "    \"PERSON\", \"EMAIL\", \"PHONE\", \"ADDRESS\", \"CREDIT_CARD\",\n",
    "    \"BANK_ACCOUNT\", \"BANK_ROUTING\", \"SSN\", \"DRIVER_ID\", \"PASSPORT\",\n",
    "    \"DATE\", \"URL\", \"IP_ADDRESS\", \"MEDICAL_CONDITION\", \"MEDICAL_PROCEDURE\", \"MEDICATION\"\n",
    "]\n",
    "\n",
    "print(f\"Environment: {ENVIRONMENT}\")\n",
    "print(f\"S3 Bucket: {AWS_S3_BUCKET_NAME}\")\n",
    "print(f\"Region: {AWS_S3_REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10112fb",
   "metadata": {},
   "source": [
    "## 3. AWS Transcriber Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e230cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWSTranscriber:\n",
    "    \"\"\"Handles transcription using AWS Transcribe\"\"\"\n",
    "\n",
    "    def __init__(self, region: str = AWS_S3_REGION):\n",
    "        \"\"\"Initialize AWS Transcribe and S3 clients\"\"\"\n",
    "        self.transcribe_client = boto3.client(\n",
    "            \"transcribe\",\n",
    "            region_name=region,\n",
    "            aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        )\n",
    "        self.s3_client = boto3.client(\n",
    "            \"s3\",\n",
    "            region_name=region,\n",
    "            aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        )\n",
    "\n",
    "    def upload_audio_to_s3(self, audio_file_path: str, call_id: str) -> Optional[str]:\n",
    "        \"\"\"Upload audio file to S3\"\"\"\n",
    "        print(f\"\\nüì§ Uploading audio file to S3: {audio_file_path}\")\n",
    "\n",
    "        if not os.path.exists(audio_file_path):\n",
    "            print(f\"‚ùå File not found: {audio_file_path}\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            s3_key = f\"{ENVIRONMENT.lower()}/audio/{call_id}/original.wav\"\n",
    "            self.s3_client.upload_file(audio_file_path, AWS_S3_BUCKET_NAME, s3_key)\n",
    "            s3_uri = f\"s3://{AWS_S3_BUCKET_NAME}/{s3_key}\"\n",
    "            print(f\"‚úÖ Audio uploaded successfully\")\n",
    "            print(f\"   S3 URI: {s3_uri}\")\n",
    "            return s3_uri\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error uploading audio: {e}\")\n",
    "            return None\n",
    "\n",
    "    def submit_transcription(self, s3_uri: str, call_id: str) -> Optional[str]:\n",
    "        \"\"\"Submit audio for transcription\"\"\"\n",
    "        print(f\"\\nüìù Submitting for transcription...\")\n",
    "        job_name = f\"transcribe-{call_id}-{int(time.time())}\"\n",
    "\n",
    "        try:\n",
    "            response = self.transcribe_client.start_transcription_job(\n",
    "                TranscriptionJobName=job_name,\n",
    "                Media={\"MediaFileUri\": s3_uri},\n",
    "                MediaFormat=\"wav\",\n",
    "                LanguageCode=\"en-US\",\n",
    "                OutputBucketName=AWS_S3_BUCKET_NAME,\n",
    "                OutputKey=f\"{ENVIRONMENT.lower()}/transcripts/{call_id}/\",\n",
    "                Settings={\n",
    "                    \"ShowAlternatives\": False,\n",
    "                    \"MaxSpeakerLabels\": 2,\n",
    "                    \"ShowSpeakerLabels\": True,\n",
    "                    \"VocabularyFilterMethod\": \"mask\",\n",
    "                },\n",
    "            )\n",
    "            print(f\"‚úÖ Transcription job submitted: {job_name}\")\n",
    "            return job_name\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error submitting transcription: {e}\")\n",
    "            return None\n",
    "\n",
    "    def wait_for_completion(self, job_name: str, max_retries: int = 120) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Poll AWS Transcribe until transcription is complete\"\"\"\n",
    "        print(f\"\\n‚è≥ Waiting for transcription to complete...\")\n",
    "        retry_count = 0\n",
    "\n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                response = self.transcribe_client.get_transcription_job(\n",
    "                    TranscriptionJobName=job_name\n",
    "                )\n",
    "                job = response[\"TranscriptionJob\"]\n",
    "                status = job[\"TranscriptionJobStatus\"]\n",
    "\n",
    "                if status == \"COMPLETED\":\n",
    "                    print(f\"‚úÖ Transcription completed!\")\n",
    "                    return job\n",
    "                elif status == \"FAILED\":\n",
    "                    error = job.get(\"FailureReason\", \"Unknown error\")\n",
    "                    print(f\"‚ùå Transcription failed: {error}\")\n",
    "                    return None\n",
    "                else:\n",
    "                    print(f\"   Status: {status} ({retry_count * 10}s elapsed)\")\n",
    "                    time.sleep(10)\n",
    "                    retry_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error polling status: {e}\")\n",
    "                return None\n",
    "\n",
    "        print(f\"‚ùå Transcription timeout\")\n",
    "        return None\n",
    "\n",
    "    def get_transcript_content(self, job: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Download and parse transcription result\"\"\"\n",
    "        try:\n",
    "            transcript_uri = job[\"Transcript\"][\"TranscriptFileUri\"]\n",
    "            print(f\"\\nüì• Downloading transcript...\")\n",
    "\n",
    "            if transcript_uri.startswith(\"https://\"):\n",
    "                response = requests.get(transcript_uri)\n",
    "                response.raise_for_status()\n",
    "                content = response.json()\n",
    "            else:\n",
    "                s3_parts = transcript_uri.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "                bucket = s3_parts[0]\n",
    "                key = s3_parts[1]\n",
    "                response = self.s3_client.get_object(Bucket=bucket, Key=key)\n",
    "                content = json.loads(response[\"Body\"].read())\n",
    "\n",
    "            print(f\"‚úÖ Transcript downloaded\")\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error downloading transcript: {e}\")\n",
    "            return None\n",
    "\n",
    "    def delete_transcription_job(self, job_name: str) -> bool:\n",
    "        \"\"\"Delete transcription job\"\"\"\n",
    "        try:\n",
    "            self.transcribe_client.delete_transcription_job(TranscriptionJobName=job_name)\n",
    "            print(f\"\\nüóëÔ∏è  Transcription job deleted\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error deleting job: {e}\")\n",
    "            return False\n",
    "\n",
    "print(\"‚úÖ AWSTranscriber class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f74307a",
   "metadata": {},
   "source": [
    "## 4. PII Redactor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ced79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIIRedactor:\n",
    "    \"\"\"Handles PII detection and redaction using AWS Comprehend\"\"\"\n",
    "\n",
    "    def __init__(self, region: str = AWS_S3_REGION):\n",
    "        self.comprehend_client = boto3.client(\n",
    "            \"comprehend\",\n",
    "            region_name=region,\n",
    "            aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        )\n",
    "\n",
    "    def detect_pii_entities(self, text: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Detect PII entities in text\"\"\"\n",
    "        try:\n",
    "            response = self.comprehend_client.detect_pii_entities(\n",
    "                Text=text, LanguageCode=\"en\"\n",
    "            )\n",
    "            entities = response.get(\"Entities\", [])\n",
    "            print(f\"\\nüîí PII Detection: {len(entities)} entities found\")\n",
    "\n",
    "            entity_types = {}\n",
    "            for entity in entities:\n",
    "                entity_type = entity.get(\"Type\")\n",
    "                entity_types[entity_type] = entity_types.get(entity_type, 0) + 1\n",
    "\n",
    "            if entity_types:\n",
    "                for entity_type, count in sorted(entity_types.items()):\n",
    "                    print(f\"   - {entity_type}: {count}\")\n",
    "\n",
    "            return entities\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error detecting PII: {e}\")\n",
    "            return []\n",
    "\n",
    "    def redact_text(self, text: str, entities: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"Redact PII entities from text\"\"\"\n",
    "        if not entities:\n",
    "            return text\n",
    "\n",
    "        sorted_entities = sorted(entities, key=lambda x: x[\"BeginOffset\"], reverse=True)\n",
    "        redacted_text = text\n",
    "\n",
    "        for entity in sorted_entities:\n",
    "            entity_type = entity.get(\"Type\", \"UNKNOWN\")\n",
    "            begin = entity.get(\"BeginOffset\")\n",
    "            end = entity.get(\"EndOffset\")\n",
    "            if begin is not None and end is not None:\n",
    "                placeholder = f\"[{entity_type}]\"\n",
    "                redacted_text = redacted_text[:begin] + placeholder + redacted_text[end:]\n",
    "\n",
    "        return redacted_text\n",
    "\n",
    "    def extract_word_timings(self, transcript_content: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Extract word-level timing from transcript\"\"\"\n",
    "        words = []\n",
    "        try:\n",
    "            results = transcript_content.get(\"results\", {})\n",
    "            items = results.get(\"items\", [])\n",
    "\n",
    "            for item in items:\n",
    "                if item.get(\"type\") == \"pronunciation\":\n",
    "                    words.append({\n",
    "                        \"word\": item.get(\"alternatives\", [{}])[0].get(\"content\", \"\"),\n",
    "                        \"start_time\": float(item.get(\"start_time\", 0)),\n",
    "                        \"end_time\": float(item.get(\"end_time\", 0)),\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"   Warning: Could not extract word timings: {e}\")\n",
    "\n",
    "        return words\n",
    "\n",
    "    def redact_audio(self, audio_file_path: str, original_text: str,\n",
    "                     entities: List[Dict[str, Any]], transcript_content: Optional[Dict[str, Any]] = None,\n",
    "                     redaction_mode: str = \"tone\") -> Optional[bytes]:\n",
    "        \"\"\"Redact audio by replacing PII segments\"\"\"\n",
    "        try:\n",
    "            print(f\"\\nüîä Redacting audio ({redaction_mode} mode)...\")\n",
    "            if not entities:\n",
    "                print(\"   No PII to redact\")\n",
    "                return None\n",
    "\n",
    "            audio = AudioSegment.from_file(audio_file_path)\n",
    "            audio_duration_ms = len(audio)\n",
    "            print(f\"   Audio duration: {audio_duration_ms / 1000:.2f}s\")\n",
    "\n",
    "            # Use word-level timing if available\n",
    "            words = self.extract_word_timings(transcript_content) if transcript_content else []\n",
    "            if words:\n",
    "                print(f\"   Using word-level timing ({len(words)} words)\")\n",
    "\n",
    "            sorted_entities = sorted(entities, key=lambda x: x[\"BeginOffset\"], reverse=True)\n",
    "\n",
    "            for entity in sorted_entities:\n",
    "                begin_char = entity.get(\"BeginOffset\")\n",
    "                end_char = entity.get(\"EndOffset\")\n",
    "                entity_type = entity.get(\"Type\", \"UNKNOWN\")\n",
    "\n",
    "                if begin_char is not None and end_char is not None:\n",
    "                    # Estimate timing (simplified)\n",
    "                    chars_per_second = len(original_text) / (audio_duration_ms / 1000)\n",
    "                    start_ms = int((begin_char / chars_per_second) * 1000)\n",
    "                    end_ms = int((end_char / chars_per_second) * 1000)\n",
    "\n",
    "                    start_ms = max(0, start_ms)\n",
    "                    end_ms = min(audio_duration_ms, end_ms)\n",
    "                    duration_ms = end_ms - start_ms\n",
    "\n",
    "                    if duration_ms > 50:\n",
    "                        # Create tone for redaction\n",
    "                        tone = Sine(1000).to_audio_segment(duration=duration_ms)\n",
    "                        redaction_segment = tone - 15\n",
    "                        audio = audio[:start_ms] + redaction_segment + audio[end_ms:]\n",
    "                        print(f\"   ‚úì Redacted {entity_type} at {start_ms}ms-{end_ms}ms\")\n",
    "\n",
    "            audio_bytes = audio.export(format=\"wav\").read()\n",
    "            print(f\"‚úÖ Audio redaction completed\")\n",
    "            return audio_bytes\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error redacting audio: {e}\")\n",
    "            return None\n",
    "\n",
    "print(\"‚úÖ PIIRedactor class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95840ed",
   "metadata": {},
   "source": [
    "## 5. Gemini Sentiment Analyzer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiSentimentAnalyzer:\n",
    "    \"\"\"Handles sentiment analysis using Google Gemini API\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "    def format_time(self, seconds: float) -> str:\n",
    "        \"\"\"Convert seconds to MM:SS format\"\"\"\n",
    "        minutes = int(seconds // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        return f\"{minutes:02d}:{secs:02d}\"\n",
    "\n",
    "    def extract_speaker_segments(self, transcript_content: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Extract speaker segments from AWS Transcribe results\"\"\"\n",
    "        segments = []\n",
    "        try:\n",
    "            results = transcript_content.get(\"results\", {})\n",
    "            items = results.get(\"items\", [])\n",
    "            speaker_labels = results.get(\"speaker_labels\", {})\n",
    "            segments_data = speaker_labels.get(\"segments\", [])\n",
    "\n",
    "            for segment in segments_data:\n",
    "                speaker = segment.get(\"speaker_label\", \"Unknown\")\n",
    "                start_time = float(segment.get(\"start_time\", 0))\n",
    "                end_time = float(segment.get(\"end_time\", 0))\n",
    "\n",
    "                text_parts = []\n",
    "                for i, item in enumerate(items):\n",
    "                    if item.get(\"type\") == \"pronunciation\":\n",
    "                        item_start = float(item.get(\"start_time\", 0))\n",
    "                        item_end = float(item.get(\"end_time\", 0))\n",
    "\n",
    "                        if item_start >= start_time and item_end <= end_time:\n",
    "                            word = item.get(\"alternatives\", [{}])[0].get(\"content\", \"\")\n",
    "                            text_parts.append(word)\n",
    "\n",
    "                            if i + 1 < len(items) and items[i + 1].get(\"type\") == \"punctuation\":\n",
    "                                punct = items[i + 1].get(\"alternatives\", [{}])[0].get(\"content\", \"\")\n",
    "                                if punct and text_parts:\n",
    "                                    text_parts[-1] = text_parts[-1] + punct\n",
    "\n",
    "                text = \" \".join(text_parts)\n",
    "                if text.strip():\n",
    "                    segments.append({\n",
    "                        \"speaker\": speaker,\n",
    "                        \"text\": text.strip(),\n",
    "                        \"start_time\": start_time,\n",
    "                        \"end_time\": end_time\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extracting segments: {e}\")\n",
    "\n",
    "        return segments\n",
    "\n",
    "    def merge_consecutive_segments(self, segments: List[Dict[str, Any]], max_gap: float = 2.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Merge consecutive segments from same speaker and fix diarization errors\"\"\"\n",
    "        if not segments:\n",
    "            return segments\n",
    "\n",
    "        # First pass: Fix speaker diarization errors\n",
    "        fixed_segments = []\n",
    "        i = 0\n",
    "        while i < len(segments):\n",
    "            current = segments[i]\n",
    "\n",
    "            if i + 1 < len(segments):\n",
    "                next_seg = segments[i + 1]\n",
    "                current_duration = current[\"end_time\"] - current[\"start_time\"]\n",
    "                next_duration = next_seg[\"end_time\"] - next_seg[\"start_time\"]\n",
    "                time_gap = next_seg[\"start_time\"] - current[\"end_time\"]\n",
    "\n",
    "                # Detect suspicious short segments alternating speakers\n",
    "                if (current_duration < 3.0 and next_duration < 3.0 and\n",
    "                    time_gap <= 0.5 and current[\"speaker\"] != next_seg[\"speaker\"]):\n",
    "\n",
    "                    cluster = [current]\n",
    "                    j = i + 1\n",
    "                    while j < len(segments):\n",
    "                        seg = segments[j]\n",
    "                        seg_duration = seg[\"end_time\"] - seg[\"start_time\"]\n",
    "                        gap = seg[\"start_time\"] - cluster[-1][\"end_time\"]\n",
    "\n",
    "                        if seg_duration < 3.0 and gap <= 0.5:\n",
    "                            cluster.append(seg)\n",
    "                            j += 1\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    # Merge cluster if 3+ segments\n",
    "                    if len(cluster) >= 3:\n",
    "                        if i > 0:\n",
    "                            correct_speaker = segments[i - 1][\"speaker\"]\n",
    "                        elif i + len(cluster) < len(segments):\n",
    "                            next_speaker = segments[i + len(cluster)][\"speaker\"]\n",
    "                            correct_speaker = \"spk_0\" if next_speaker == \"spk_1\" else \"spk_1\"\n",
    "                        else:\n",
    "                            correct_speaker = cluster[0][\"speaker\"]\n",
    "\n",
    "                        merged_text = \" \".join(seg[\"text\"] for seg in cluster)\n",
    "                        merged_segment = {\n",
    "                            \"speaker\": correct_speaker,\n",
    "                            \"text\": merged_text.strip(),\n",
    "                            \"start_time\": cluster[0][\"start_time\"],\n",
    "                            \"end_time\": cluster[-1][\"end_time\"]\n",
    "                        }\n",
    "                        fixed_segments.append(merged_segment)\n",
    "                        i = j\n",
    "                        continue\n",
    "\n",
    "            fixed_segments.append(current)\n",
    "            i += 1\n",
    "\n",
    "        # Second pass: Merge same-speaker segments\n",
    "        if not fixed_segments:\n",
    "            return []\n",
    "\n",
    "        merged = []\n",
    "        current_segment = fixed_segments[0].copy()\n",
    "\n",
    "        for segment in fixed_segments[1:]:\n",
    "            if (segment[\"speaker\"] == current_segment[\"speaker\"] and\n",
    "                segment[\"start_time\"] - current_segment[\"end_time\"] <= max_gap):\n",
    "                current_segment[\"text\"] += \" \" + segment[\"text\"]\n",
    "                current_segment[\"end_time\"] = segment[\"end_time\"]\n",
    "            else:\n",
    "                merged.append(current_segment)\n",
    "                current_segment = segment.copy()\n",
    "\n",
    "        merged.append(current_segment)\n",
    "        return merged\n",
    "\n",
    "    def analyze_sentiment_with_gemini(self, segments: List[Dict[str, Any]],\n",
    "                                     full_transcript: str = \"\",\n",
    "                                     pii_entities: List[Dict[str, Any]] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Analyze sentiment for each segment using Gemini\"\"\"\n",
    "        print(f\"\\nü§ñ Analyzing sentiment with Gemini for {len(segments)} segments...\")\n",
    "        analyzed_segments = []\n",
    "\n",
    "        try:\n",
    "            prompt = \"\"\"Analyze this customer service conversation. For each segment, provide:\n",
    "1. sentiment: \"positive\", \"negative\", or \"neutral\"\n",
    "2. confidence: 0.0-1.0\n",
    "3. tone_note: Brief description\n",
    "\n",
    "Segments:\\n\"\"\"\n",
    "\n",
    "            for i, segment in enumerate(segments, 1):\n",
    "                prompt += f\"{i}. [{segment['speaker']}]: {segment['text']}\\n\"\n",
    "\n",
    "            prompt += \"\\nReturn ONLY valid JSON array: [{\\\"sentiment\\\": \\\"neutral\\\", \\\"confidence\\\": 0.9, \\\"tone_note\\\": \\\"...\\\"}]\"\n",
    "\n",
    "            response = self.model.generate_content(prompt)\n",
    "            response_text = response.text.strip()\n",
    "\n",
    "            if \"```json\" in response_text:\n",
    "                json_start = response_text.find(\"```json\") + 7\n",
    "                json_end = response_text.find(\"```\", json_start)\n",
    "                response_text = response_text[json_start:json_end].strip()\n",
    "\n",
    "            sentiment_results = json.loads(response_text)\n",
    "\n",
    "            for i, segment in enumerate(segments):\n",
    "                speaker_label = segment[\"speaker\"].replace(\"spk_\", \"Speaker \")\n",
    "                if \"0\" in speaker_label:\n",
    "                    speaker_label = \"Agent\"\n",
    "                elif \"1\" in speaker_label:\n",
    "                    speaker_label = \"Customer\"\n",
    "\n",
    "                sentiment_data = sentiment_results[i] if i < len(sentiment_results) else {}\n",
    "\n",
    "                analyzed_segments.append({\n",
    "                    \"order\": i + 1,\n",
    "                    \"speaker\": speaker_label,\n",
    "                    \"text\": segment[\"text\"],\n",
    "                    \"start_time\": self.format_time(segment[\"start_time\"]),\n",
    "                    \"end_time\": self.format_time(segment[\"end_time\"]),\n",
    "                    \"sentiment\": sentiment_data.get(\"sentiment\", \"neutral\"),\n",
    "                    \"confidence\": sentiment_data.get(\"confidence\", 0.9),\n",
    "                    \"tone_note\": sentiment_data.get(\"tone_note\", \"Neutral tone\")\n",
    "                })\n",
    "\n",
    "            print(f\"‚úÖ Sentiment analysis completed\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error with Gemini: {e}\")\n",
    "            # Fallback with neutral sentiment\n",
    "            for i, segment in enumerate(segments):\n",
    "                speaker_label = \"Agent\" if \"0\" in segment[\"speaker\"] else \"Customer\"\n",
    "                analyzed_segments.append({\n",
    "                    \"order\": i + 1,\n",
    "                    \"speaker\": speaker_label,\n",
    "                    \"text\": segment[\"text\"],\n",
    "                    \"start_time\": self.format_time(segment[\"start_time\"]),\n",
    "                    \"end_time\": self.format_time(segment[\"end_time\"]),\n",
    "                    \"sentiment\": \"neutral\",\n",
    "                    \"confidence\": 0.9,\n",
    "                    \"tone_note\": \"Neutral tone\"\n",
    "                })\n",
    "\n",
    "        return analyzed_segments\n",
    "\n",
    "print(\"‚úÖ GeminiSentimentAnalyzer class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b8449",
   "metadata": {},
   "source": [
    "## 6. S3 Manager Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64bc63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3Manager:\n",
    "    \"\"\"Handles S3 operations for storing redacted audio\"\"\"\n",
    "\n",
    "    def __init__(self, access_key: str, secret_key: str, bucket_name: str, region: str = \"us-east-1\"):\n",
    "        self.bucket_name = bucket_name\n",
    "        self.region = region\n",
    "        self.s3_client = boto3.client(\n",
    "            \"s3\",\n",
    "            aws_access_key_id=access_key,\n",
    "            aws_secret_access_key=secret_key,\n",
    "            region_name=region,\n",
    "        )\n",
    "\n",
    "    def upload_redacted_audio(self, audio_bytes: bytes, call_id: str, audio_format: str = \"wav\") -> Optional[str]:\n",
    "        \"\"\"Upload redacted audio to S3\"\"\"\n",
    "        print(f\"\\n‚òÅÔ∏è  Uploading redacted audio to S3...\")\n",
    "        try:\n",
    "            s3_key = f\"{ENVIRONMENT.lower()}/transcriptions/{call_id}/redacted_audio.{audio_format}\"\n",
    "            content_type = \"audio/wav\" if audio_format == \"wav\" else \"audio/mpeg\"\n",
    "\n",
    "            self.s3_client.put_object(\n",
    "                Bucket=self.bucket_name,\n",
    "                Key=s3_key,\n",
    "                Body=audio_bytes,\n",
    "                ContentType=content_type,\n",
    "            )\n",
    "\n",
    "            s3_url = f\"https://{self.bucket_name}.s3.{self.region}.amazonaws.com/{s3_key}\"\n",
    "            print(f\"‚úÖ Uploaded successfully ({len(audio_bytes) / (1024*1024):.2f} MB)\")\n",
    "            return s3_url\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error uploading to S3: {e}\")\n",
    "            return None\n",
    "\n",
    "print(\"‚úÖ S3Manager class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0bfd29",
   "metadata": {},
   "source": [
    "## 7. Main Processing Pipeline\n",
    "\n",
    "Set your audio file path and call ID here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3538991",
   "metadata": {},
   "source": [
    "### Option A: Upload Audio File (Interactive Widget)\n",
    "\n",
    "Use the file upload widget below to select an audio file from your computer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aad2a1",
   "metadata": {},
   "source": [
    "### Available Audio Files in Current Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List audio files in current directory\n",
    "import glob\n",
    "\n",
    "audio_extensions = ['*.mp3', '*.wav', '*.m4a', '*.flac', '*.ogg', '*.aac']\n",
    "audio_files = []\n",
    "\n",
    "for ext in audio_extensions:\n",
    "    audio_files.extend(glob.glob(ext))\n",
    "\n",
    "if audio_files:\n",
    "    print(f\"üìÇ Found {len(audio_files)} audio file(s) in current directory:\")\n",
    "    for i, file in enumerate(audio_files, 1):\n",
    "        size = os.path.getsize(file) / (1024 * 1024)\n",
    "        print(f\"   {i}. {file} ({size:.2f} MB)\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No audio files found in current directory\")\n",
    "    print(\"   You can upload a file using the widget below or specify a path manually\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c06f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FileUpload, Button, Output, VBox, HBox, Label\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create file upload widget\n",
    "uploader = FileUpload(\n",
    "    accept='.mp3,.wav,.m4a,.flac',  # Accept common audio formats\n",
    "    multiple=False,\n",
    "    description='Choose Audio File'\n",
    ")\n",
    "\n",
    "# Output area for messages\n",
    "upload_output = Output()\n",
    "\n",
    "# Variable to store uploaded file info\n",
    "uploaded_audio_info = {'filename': None, 'content': None}\n",
    "\n",
    "def on_upload_change(change):\n",
    "    \"\"\"Handle file upload\"\"\"\n",
    "    with upload_output:\n",
    "        clear_output()\n",
    "        if uploader.value:\n",
    "            # Get the uploaded file\n",
    "            uploaded_file = list(uploader.value.values())[0]\n",
    "            filename = uploaded_file['metadata']['name']\n",
    "            content = uploaded_file['content']\n",
    "\n",
    "            # Save to disk\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(content)\n",
    "\n",
    "            uploaded_audio_info['filename'] = filename\n",
    "            uploaded_audio_info['content'] = content\n",
    "\n",
    "            print(f\"‚úÖ File uploaded: {filename}\")\n",
    "            print(f\"   Size: {len(content) / (1024*1024):.2f} MB\")\n",
    "            print(f\"   Saved to: {os.path.abspath(filename)}\")\n",
    "\n",
    "uploader.observe(on_upload_change, names='value')\n",
    "\n",
    "# Display the widget\n",
    "display(VBox([\n",
    "    Label('Upload an audio file (MP3, WAV, M4A, FLAC):'),\n",
    "    uploader,\n",
    "    upload_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40a8a50",
   "metadata": {},
   "source": [
    "### Option B: Specify Audio File Path\n",
    "\n",
    "Or manually specify the path to an audio file on your system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use uploaded file from widget above\n",
    "if uploaded_audio_info['filename']:\n",
    "    AUDIO_FILE = uploaded_audio_info['filename']\n",
    "    print(f\"‚úÖ Using uploaded file: {AUDIO_FILE}\")\n",
    "else:\n",
    "    # Option 2: Manually specify path\n",
    "    AUDIO_FILE = \"10min.mp3\"  # Change this to your audio file path\n",
    "    print(f\"üìÅ Using specified file: {AUDIO_FILE}\")\n",
    "\n",
    "# Verify file exists\n",
    "if os.path.exists(AUDIO_FILE):\n",
    "    file_size = os.path.getsize(AUDIO_FILE) / (1024 * 1024)\n",
    "    print(f\"   File size: {file_size:.2f} MB\")\n",
    "    print(f\"   Full path: {os.path.abspath(AUDIO_FILE)}\")\n",
    "else:\n",
    "    print(f\"‚ùå File not found: {AUDIO_FILE}\")\n",
    "    print(f\"   Please upload a file using the widget above or check the file path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6250392",
   "metadata": {},
   "source": [
    "### Generate Call ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe94570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique call ID with timestamp\n",
    "CALL_ID = f\"test_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "print(f\"üìã Call ID: {CALL_ID}\")\n",
    "print(f\"üéôÔ∏è  Ready to process: {AUDIO_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19cf6b",
   "metadata": {},
   "source": [
    "### Step 1: Initialize Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all services\n",
    "transcriber = AWSTranscriber()\n",
    "pii_redactor = PIIRedactor()\n",
    "gemini_analyzer = GeminiSentimentAnalyzer(api_key=GEMINI_API_KEY)\n",
    "s3_manager = S3Manager(\n",
    "    access_key=AWS_ACCESS_KEY_ID,\n",
    "    secret_key=AWS_SECRET_ACCESS_KEY,\n",
    "    bucket_name=AWS_S3_BUCKET_NAME,\n",
    "    region=AWS_S3_REGION,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ All services initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54712c",
   "metadata": {},
   "source": [
    "### Step 2: Upload Audio to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uri = transcriber.upload_audio_to_s3(AUDIO_FILE, CALL_ID)\n",
    "if not s3_uri:\n",
    "    raise Exception(\"Failed to upload audio to S3\")\n",
    "\n",
    "print(f\"S3 URI: {s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9bf43c",
   "metadata": {},
   "source": [
    "### Step 3: Submit Transcription Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2047b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = transcriber.submit_transcription(s3_uri, CALL_ID)\n",
    "if not job_name:\n",
    "    raise Exception(\"Failed to submit transcription\")\n",
    "\n",
    "print(f\"Job Name: {job_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb937363",
   "metadata": {},
   "source": [
    "### Step 4: Wait for Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a9eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = transcriber.wait_for_completion(job_name)\n",
    "if not job:\n",
    "    raise Exception(\"Transcription failed or timed out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6da64",
   "metadata": {},
   "source": [
    "### Step 5: Download Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_content = transcriber.get_transcript_content(job)\n",
    "if not transcript_content:\n",
    "    raise Exception(\"Failed to download transcript\")\n",
    "\n",
    "# Extract text\n",
    "results = transcript_content.get(\"results\", {})\n",
    "transcriptions = results.get(\"transcripts\", [])\n",
    "original_text = transcriptions[0].get(\"transcript\", \"\") if transcriptions else \"\"\n",
    "\n",
    "print(f\"\\nOriginal Transcript ({len(original_text)} chars):\")\n",
    "print(original_text[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aea44e",
   "metadata": {},
   "source": [
    "### Step 6: Detect and Redact PII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11eb7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect PII\n",
    "pii_entities = pii_redactor.detect_pii_entities(original_text)\n",
    "\n",
    "# Redact text\n",
    "redacted_text = pii_redactor.redact_text(original_text, pii_entities)\n",
    "\n",
    "print(f\"\\nRedacted Transcript:\")\n",
    "print(redacted_text[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcf1bd8",
   "metadata": {},
   "source": [
    "### Step 7: Speaker Segmentation & Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09255d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract speaker segments\n",
    "speaker_segments = gemini_analyzer.extract_speaker_segments(transcript_content)\n",
    "print(f\"Original segments: {len(speaker_segments)}\")\n",
    "\n",
    "# Merge consecutive segments\n",
    "merged_segments = gemini_analyzer.merge_consecutive_segments(speaker_segments, max_gap=2.0)\n",
    "print(f\"Merged segments: {len(merged_segments)}\")\n",
    "\n",
    "# Analyze sentiment\n",
    "sentiment_analysis_results = gemini_analyzer.analyze_sentiment_with_gemini(\n",
    "    merged_segments,\n",
    "    full_transcript=original_text,\n",
    "    pii_entities=pii_entities\n",
    ")\n",
    "\n",
    "# Save results\n",
    "sentiment_file = f\"sentiment_analysis_{CALL_ID}.json\"\n",
    "with open(sentiment_file, \"w\") as f:\n",
    "    json.dump(sentiment_analysis_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Sentiment analysis saved to: {sentiment_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f0c916",
   "metadata": {},
   "source": [
    "### Step 8: Preview Sentiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5657ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüìä Sentiment Analysis Preview (first 5 segments):\\n\")\n",
    "for segment in sentiment_analysis_results[:5]:\n",
    "    print(f\"Order {segment['order']}: {segment['speaker']}\")\n",
    "    print(f\"  Text: {segment['text'][:80]}...\")\n",
    "    print(f\"  Time: {segment['start_time']} - {segment['end_time']}\")\n",
    "    print(f\"  Sentiment: {segment['sentiment']} (confidence: {segment['confidence']:.2f})\")\n",
    "    print(f\"  Tone: {segment['tone_note']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1435118",
   "metadata": {},
   "source": [
    "### Step 9: Redact Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "redacted_audio_bytes = pii_redactor.redact_audio(\n",
    "    AUDIO_FILE,\n",
    "    original_text,\n",
    "    pii_entities,\n",
    "    transcript_content=transcript_content,\n",
    "    redaction_mode=\"tone\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747295d0",
   "metadata": {},
   "source": [
    "### Step 10: Upload Redacted Audio to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e38d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "redacted_audio_s3_url = None\n",
    "if redacted_audio_bytes:\n",
    "    redacted_audio_s3_url = s3_manager.upload_redacted_audio(\n",
    "        redacted_audio_bytes,\n",
    "        CALL_ID,\n",
    "        audio_format=\"wav\"\n",
    "    )\n",
    "    print(f\"Redacted audio URL: {redacted_audio_s3_url}\")\n",
    "else:\n",
    "    print(\"No redacted audio to upload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace9cbcb",
   "metadata": {},
   "source": [
    "### Step 11: Cleanup & Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c29b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete transcription job\n",
    "transcriber.delete_transcription_job(job_name)\n",
    "\n",
    "# Print final summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ PROCESSING COMPLETED\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nüìä Results Summary:\")\n",
    "print(f\"   Call ID: {CALL_ID}\")\n",
    "print(f\"   Original transcript: {len(original_text)} characters\")\n",
    "print(f\"   Redacted transcript: {len(redacted_text)} characters\")\n",
    "print(f\"   PII entities found: {len(pii_entities)}\")\n",
    "print(f\"   Speaker segments: {len(sentiment_analysis_results)}\")\n",
    "print(f\"   Sentiment file: {sentiment_file}\")\n",
    "print(f\"   Original audio: {s3_uri}\")\n",
    "if redacted_audio_s3_url:\n",
    "    print(f\"   Redacted audio: {redacted_audio_s3_url}\")\n",
    "print(f\"\\n{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
